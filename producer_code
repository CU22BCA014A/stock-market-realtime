"""
PRODUCER.PY - Kafka Producer for Real-Time Stock Market Data
Ingests stock price data and publishes to Kafka topic
"""

import json
import time
import random
from datetime import datetime
from kafka import KafkaProducer
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuration
KAFKA_BROKER = 'localhost:9092'
KAFKA_TOPIC = 'stock-prices'
STOCKS = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'AMZN']

# Simulated price ranges (realistic stock prices)
PRICE_RANGES = {
    'AAPL': (150, 200),
    'GOOGL': (100, 150),
    'MSFT': (300, 350),
    'TSLA': (200, 300),
    'AMZN': (150, 200)
}

def generate_stock_data(symbol):
    """Generate realistic simulated stock data"""
    min_price, max_price = PRICE_RANGES[symbol]
    
    price = random.uniform(min_price, max_price)
    volume = random.randint(1000000, 10000000)
    open_price = price + random.uniform(-5, 5)
    close_price = price + random.uniform(-2, 2)
    high_price = max(price, open_price, close_price) + random.uniform(0, 2)
    low_price = min(price, open_price, close_price) - random.uniform(0, 2)
    
    return {
        'symbol': symbol,
        'price': round(price, 2),
        'volume': volume,
        'open_price': round(open_price, 2),
        'close_price': round(close_price, 2),
        'high_price': round(high_price, 2),
        'low_price': round(low_price, 2),
        'timestamp': datetime.now().isoformat(),
        'change_pct': round((price - open_price) / open_price * 100, 2)
    }

def main():
    """Main producer function"""
    try:
        # Initialize Kafka Producer
        producer = KafkaProducer(
            bootstrap_servers=[KAFKA_BROKER],
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            retries=3,
            acks='all'
        )
        
        logger.info(f"‚úÖ Connected to Kafka broker: {KAFKA_BROKER}")
        logger.info(f"üìä Publishing to topic: {KAFKA_TOPIC}")
        logger.info("üöÄ Starting data stream...")
        
        message_count = 0
        
        # Continuous data generation
        while True:
            for stock in STOCKS:
                data = generate_stock_data(stock)
                
                # Publish to Kafka
                future = producer.send(KAFKA_TOPIC, value=data)
                record_metadata = future.get(timeout=10)
                
                message_count += 1
                logger.info(
                    f"üì§ [{message_count}] {stock}: ${data['price']} | "
                    f"Volume: {data['volume']:,} | Change: {data['change_pct']:+.2f}% | "
                    f"Partition: {record_metadata.partition} | "
                    f"Offset: {record_metadata.offset}"
                )
            
            # Wait 5 seconds before next batch
            time.sleep(5)
    
    except Exception as e:
        logger.error(f"‚ùå Error in producer: {str(e)}")
        raise
    finally:
        producer.flush()
        producer.close()
        logger.info("Producer closed")

if __name__ == '__main__':
    main()
